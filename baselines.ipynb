{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9ff570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data1 = pd.read_csv('datasets/cleaned_lightpath_dataset.csv')\n",
    "target1 = pd.read_csv('datasets/cleaned_lightpath_target.csv')\n",
    "\n",
    "data2 = pd.read_csv('datasets/cleaned_lightpath_dataset_2.csv')\n",
    "target2 = pd.read_csv('datasets/cleaned_lightpath_target_2.csv')\n",
    "\n",
    "data_5 = pd.read_csv('datasets/data1_plus_5.csv')\n",
    "target_5 = pd.read_csv('datasets/target1_plus_5.csv')\n",
    "\n",
    "data_5_balanced = pd.read_csv('datasets/data1_plus_5_balanced.csv')\n",
    "target_5_balanced = pd.read_csv('datasets/target1_plus_5_balanced.csv')\n",
    "\n",
    "data_10 = pd.read_csv('datasets/data1_plus_10.csv')\n",
    "target_10 = pd.read_csv('datasets/target1_plus_10.csv')\n",
    "\n",
    "data_10_balanced = pd.read_csv('datasets/data1_plus_10_balanced.csv')\n",
    "target_10_balanced = pd.read_csv('datasets/target1_plus_10_balanced.csv')\n",
    "\n",
    "data15 = pd.read_csv('datasets/data1_plus_15.csv')\n",
    "target15 = pd.read_csv('datasets/target1_plus_15.csv')\n",
    "\n",
    "data15_balanced = pd.read_csv('datasets/data1_plus_15_balanced.csv')\n",
    "target15_balanced = pd.read_csv('datasets/target1_plus_15_balanced.csv')\n",
    "\n",
    "data20 = pd.read_csv('datasets/data1_plus_20.csv')\n",
    "target20 = pd.read_csv('datasets/target1_plus_20.csv')\n",
    "\n",
    "data20_balanced = pd.read_csv('datasets/data1_plus_20_balanced.csv')\n",
    "target20_balanced = pd.read_csv('datasets/target1_plus_20_balanced.csv')\n",
    "\n",
    "shard1 = pd.read_csv('datasets/dataset2_shard_1.csv')\n",
    "target_shard1 = pd.read_csv('datasets/target2_shard_1.csv')\n",
    "\n",
    "shard2 = pd.read_csv('datasets/dataset2_shard_2.csv')\n",
    "target_shard2 = pd.read_csv('datasets/target2_shard_2.csv')\n",
    "\n",
    "shard3 = pd.read_csv('datasets/dataset2_shard_3.csv')\n",
    "target_shard3 = pd.read_csv('datasets/target2_shard_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import classification_report, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec438a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing = []\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except Exception:\n",
    "    missing.append(\"xgboost\")\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "except Exception:\n",
    "    missing.append(\"catboost\")\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "except Exception:\n",
    "    missing.append(\"lightgbm\")\n",
    "\n",
    "if missing:\n",
    "    raise ImportError(\n",
    "        \"Missing packages: \" + \", \".join(missing) + \". Install them before running this cell.\"\n",
    "    )\n",
    "\n",
    "# --- Datasets (train) ---\n",
    "train_datasets = [\n",
    "    (\"data1\", data1, target1),\n",
    "    (\"data_5\", data_5, target_5),\n",
    "    (\"data_5_balanced\", data_5_balanced, target_5_balanced),\n",
    "    (\"data_10\", data_10, target_10),\n",
    "    (\"data_10_balanced\", data_10_balanced, target_10_balanced),\n",
    "    (\"data_15\", data15, target15),\n",
    "    (\"data_15_balanced\", data15_balanced, target15_balanced),\n",
    "    (\"data_20\", data20, target20),\n",
    "    (\"data_20_balanced\", data20_balanced, target20_balanced),\n",
    "]\n",
    "\n",
    "# --- Datasets (evaluation) ---\n",
    "eval_datasets = [\n",
    "    (\"data2\", data2, target2),\n",
    "    (\"shard1\", shard1, target_shard1),\n",
    "    (\"shard2\", shard2, target_shard2),\n",
    "    (\"shard3\", shard3, target_shard3),\n",
    "]\n",
    "\n",
    "# --- Models (basic settings) ---\n",
    "models = [\n",
    "    (\"LogisticRegression\", make_pipeline(StandardScaler(with_mean=False), LogisticRegression(max_iter=2000, n_jobs=-1))),\n",
    "    (\"LogReg_L1\", make_pipeline(StandardScaler(with_mean=False), LogisticRegression(max_iter=5000, penalty=\"l1\", solver=\"saga\", n_jobs=-1))),\n",
    "    (\"LogReg_L2\", make_pipeline(StandardScaler(with_mean=False), LogisticRegression(max_iter=5000, penalty=\"l2\", solver=\"saga\", n_jobs=-1))),\n",
    "    (\"XGBoost\", XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=6, subsample=0.8, colsample_bytree=0.8, eval_metric=\"logloss\", n_jobs=-1, random_state=42)),\n",
    "    (\"CatBoost\", CatBoostClassifier(iterations=300, learning_rate=0.1, depth=6, random_seed=42, verbose=False)),\n",
    "    (\"LightGBM\", LGBMClassifier(n_estimators=300, learning_rate=0.05, num_leaves=31, random_state=42, n_jobs=-1)),\n",
    "    (\"RandomForest\", RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)),\n",
    "    (\"ExtraTrees\", ExtraTreesClassifier(n_estimators=300, random_state=42, n_jobs=-1)),\n",
    "]\n",
    "\n",
    "# Map 1 model to 1 dataset (cycles through models if datasets > models)\n",
    "model_cycle = cycle(models)\n",
    "training_plan = [(ds_name, X, y, *next(model_cycle)) for ds_name, X, y in train_datasets]\n",
    "\n",
    "def _prepare_xy(X_df: pd.DataFrame, y_df: pd.DataFrame):\n",
    "    X = pd.get_dummies(X_df, drop_first=False)\n",
    "    y = y_df.iloc[:, 0].values.ravel()\n",
    "    return X, y\n",
    "\n",
    "def _align_eval_columns(X_eval: pd.DataFrame, train_columns):\n",
    "    X_eval = pd.get_dummies(X_eval, drop_first=False)\n",
    "    X_eval = X_eval.reindex(columns=train_columns, fill_value=0)\n",
    "    return X_eval\n",
    "\n",
    "def _get_score(model, X_eval):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X_eval)\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        return model.decision_function(X_eval)\n",
    "    return model.predict(X_eval)\n",
    "\n",
    "results = []\n",
    "\n",
    "for train_name, X_train_df, y_train_df, model_name, model in training_plan:\n",
    "    X_train, y_train = _prepare_xy(X_train_df, y_train_df)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_columns = X_train.columns\n",
    "    for eval_name, X_eval_df, y_eval_df in eval_datasets:\n",
    "        X_eval = _align_eval_columns(X_eval_df, train_columns)\n",
    "        y_eval = y_eval_df.iloc[:, 0].values.ravel()\n",
    "        y_pred = model.predict(X_eval)\n",
    "        report = classification_report(y_eval, y_pred, output_dict=True, zero_division=0)\n",
    "        precision = report[\"weighted avg\"][\"precision\"]\n",
    "        recall = report[\"weighted avg\"][\"recall\"]\n",
    "        f1 = report[\"weighted avg\"][\"f1-score\"]\n",
    "        accuracy = report[\"accuracy\"]\n",
    "        try:\n",
    "            pr_auc = average_precision_score(y_eval, _get_score(model, X_eval), average=\"weighted\")\n",
    "        except Exception:\n",
    "            pr_auc = np.nan\n",
    "        results.append({\n",
    "            \"train_dataset\": train_name,\n",
    "            \"model\": model_name,\n",
    "            \"eval_dataset\": eval_name,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"pr_auc\": pr_auc,\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
